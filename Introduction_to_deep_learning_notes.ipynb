{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to deep learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Goal of This Talk\n",
    "- To give a sense of what deep learning is actually good for, and what it's not good for\n",
    "- To give a sense of when deep learning is the right strategy to take in your research\n",
    "\n",
    "## Outline\n",
    "1. No free lunch in AI\n",
    "2. Inductive biases and the AI set\n",
    "3. Deep architectures as a good inductive bias\n",
    "4. Making learning work in deep architectures\n",
    "5. When to use deep learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Free Lunch in AI\n",
    "The early dream of machine learning researchers was that we could develop general purpose learning algorithms that could learn well in any scenario on any dataset.\n",
    "\n",
    "However, there exists no learning algorithm that can perform better than all other learning algorithms on all tasks. \n",
    "\n",
    "**No Free Lunch Theorem for Optimization (Wolpert and MacReady, 1997)**\n",
    "- You can find the most appropriate algorithm for different problems, and each algorithm has its own applicable problems.\n",
    "- Make sure you completely understand a machine learning problem and the data involved before selecting an algorithm to use.\n",
    "- All models are only as good as the assumptions that they were created with and the data that was used to train them.\n",
    "- Simpler models like logistic regression have more bias and tend to underfit, while more complex models like neural networks have more variance and tend to overfit.\n",
    "- The best models for a given problem are somewhere in the middle of the two bias-variance extremes.\n",
    "- To find a good model for a problem, you may have to try different models and compare them using a robust cross-validation strategy. \n",
    "\n",
    "If you don't any expectations about what task you're going to apply your algorithms, you are never able to actually have an algorithm that outperforms all other algorithms on average.\n",
    "\n",
    "**You have to assume a non-flat prior over loss functions and select an algorithm that is well suited to learning that specific task if you want best performance**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inductive Biases And the AI Set\n",
    "How to select the right algorithms for AI?\n",
    "\n",
    "Three typical response categories\n",
    "\n",
    "1. Defeatism: We just have to hand-craft specific solutions to very specific task we ever want to accomplish in AI.\n",
    "2. Denial: Things like kernel machines can approximate any function, and we have bounds on their ability to generalize with regularization, so it's all good.\n",
    "3. Optimism: We can define the set of things we actually want to do with AI and design systems that are general purpose within that restricted set. But, this requires inductive biases.\n",
    "\n",
    "### Inductive Biases\n",
    "Inductive biases are assumptions that we bake into our algorithms about the sort of tasks we will be performing. They are a means of embedding prior knoweldge into an optimization system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
